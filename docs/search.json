[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my website!",
    "section": "",
    "text": "Hello! I’m Woohyung Kim, a Geography Education graduate student at Seoul National University. My academic journey is just beginning, and through this blog, I aim to share my research and discoveries in Spatial Data Science."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Idea for Master’s Thesis\n\n\n\nGNN\n\nLLM\n\n\n\ndescription\n\n\n\nWoohyung Kim\n\n\nAug 22, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-07-03-first-blog/index.html",
    "href": "posts/2024-07-03-first-blog/index.html",
    "title": "Exploratory Spatial Analysis of Regional Total Fertility Rates in South Korea: Part 1",
    "section": "",
    "text": "My first semester as a graduate student has finally ended This semester, I took a Spatial Data Mining class and wrote a term paper using GWR(Geographically Weighted Regression) and GRF(Geographic Random Forests). I want to share what I did with this blog post.\nMy goal was to see if there is spatial non-stationarity in the regional total fertility rate in South Korea. I set the Sigungu level as the study scale. Sigungu is the second-largest administrative region in South Korea.\nA dependent variable is the Total fertility rate. I used the following variables as independent variables:\nall the variables are based on data from the year 2020."
  },
  {
    "objectID": "posts/2024-07-03-first-blog/index.html#global-analysis",
    "href": "posts/2024-07-03-first-blog/index.html#global-analysis",
    "title": "Exploratory Spatial Analysis of Regional Total Fertility Rates in South Korea: Part 1",
    "section": "Global analysis",
    "text": "Global analysis\n\nCorrelation analysis\nBefore analyzing the variables locally, I conducted some global analysis.\n\nlibrary(readxl)\nTFR &lt;- read_excel(\"TFR2020.xlsx\")\nstr(TFR)\n\ntibble [251 × 9] (S3: tbl_df/tbl/data.frame)\n $ sgg       : num [1:251] 0 11010 11020 11030 11040 ...\n $ name      : chr [1:251] \"전국\" \"종로구\" \"중구\" \"용산구\" ...\n $ tfr       : num [1:251] 0.837 0.522 0.688 0.634 0.783 0.527 0.699 0.66 0.676 0.55 ...\n $ pop_den   : num [1:251] 516 6306 12887 10318 17358 ...\n $ incentive : num [1:251] 1.01 0.677 0.605 0.532 0.374 ...\n $ grad      : num [1:251] 20.6 41.1 36.3 46.4 40 ...\n $ first     : num [1:251] 30.7 32 32.1 32.2 31.6 ...\n $ under6    : num [1:251] 12.7 15.6 13.4 11 11.9 ...\n $ grdpPercap: num [1:251] 41.1 224 435.5 56.8 42.6 ...\n\nsummary(TFR)\n\n      sgg            name                tfr            pop_den        \n Min.   :    0   Length:251         Min.   :0.4450   Min.   :   18.37  \n 1st Qu.:24035   Class :character   1st Qu.:0.7845   1st Qu.:  103.45  \n Median :32310   Mode  :character   Median :0.9240   Median :  624.14  \n Mean   :29749                      Mean   :0.9548   Mean   : 3850.92  \n 3rd Qu.:36325                      3rd Qu.:1.0645   3rd Qu.: 5884.99  \n Max.   :39020                      Max.   :2.4550   Max.   :25143.33  \n   incentive           grad           first           under6      \n Min.   :0.0000   Min.   : 6.51   Min.   :28.34   Min.   : 3.831  \n 1st Qu.:0.4314   1st Qu.:12.51   1st Qu.:30.21   1st Qu.:10.662  \n Median :0.7860   Median :18.76   Median :30.66   Median :12.702  \n Mean   :1.0105   Mean   :20.61   Mean   :30.68   Mean   :12.899  \n 3rd Qu.:1.3544   3rd Qu.:25.34   3rd Qu.:31.09   3rd Qu.:14.767  \n Max.   :4.9820   Max.   :59.96   Max.   :32.49   Max.   :27.231  \n   grdpPercap    \n Min.   : 10.82  \n 1st Qu.: 26.04  \n Median : 32.87  \n Mean   : 39.34  \n 3rd Qu.: 41.70  \n Max.   :435.52  \n\n\n\nlibrary(GGally)\nTFR |&gt; \n  select(tfr, pop_den, incentive, grad, first, under6, grdpPercap) |&gt; \n  ggpairs()\n\n\n\n\n\n\n\n\nI found that some variables have skewed distributions, so I decided to apply log transformation to those variables.\n\nTFR_log &lt;- TFR |&gt; \n  mutate(\n    tfr_log = log(tfr),\n    popden_log = log(pop_den),\n    incentive_log = log(incentive + 1),\n    grad_log = log(grad),\n    grdpPercap_log = log(grdpPercap)\n  ) |&gt; \n  select(-c(tfr, grad, grdpPercap, pop_den, incentive))\n\nTFR_log |&gt; \n  select(-c(sgg, name)) |&gt; \n  relocate(tfr_log, popden_log, incentive_log, grad_log, first, under6, grdpPercap_log) |&gt; \n  ggpairs()\n\n\n\n\n\n\n\n\nNow the distributions look much better than before. In this correlation matrix, I found that there are some significant correlations between independent variables. This is called multicollinearity, and in the regression analysis, it negatively affect the results. Researchers usually address this issue by removing some variables or conducting dimension reduction techniques such as Principle Component Analysis (PCA). However, in my case, “global correlations” between independent variables do not necessarily imply “local correlations”. Therefore, I decided to use all the variables as they are.\n\n\nRegression Analysis\nI also conducted an Ordinary Least Squares Regression (OLS) to examine the relationship between dependent and independent variables.\n\nTFR_log_sgg &lt;- TFR_log[-1, ] # first row contains the value of the whole country.\nmodel_log &lt;- lm(tfr_log ~ \n                  popden_log + incentive_log + grad_log + first + under6 + grdpPercap_log,\n                data = TFR_log_sgg)\nsummary(model_log)\n\n\nCall:\nlm(formula = tfr_log ~ popden_log + incentive_log + grad_log + \n    first + under6 + grdpPercap_log, data = TFR_log_sgg)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.43705 -0.10125  0.00607  0.09694  0.58561 \n\nCoefficients:\n                 Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)     2.7979081  0.5178115   5.403          0.000000156 ***\npopden_log     -0.0847490  0.0085770  -9.881 &lt; 0.0000000000000002 ***\nincentive_log   0.1072175  0.0333750   3.213              0.00149 ** \ngrad_log        0.0805996  0.0374403   2.153              0.03232 *  \nfirst          -0.0806301  0.0168346  -4.790          0.000002909 ***\nunder6         -0.0116743  0.0034761  -3.358              0.00091 ***\ngrdpPercap_log  0.0005006  0.0221743   0.023              0.98201    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.162 on 243 degrees of freedom\nMultiple R-squared:  0.6221,    Adjusted R-squared:  0.6128 \nF-statistic: 66.68 on 6 and 243 DF,  p-value: &lt; 0.00000000000000022\n\n\nThree variables (popden_log, first, under6) showed the most significance, followed by incentive_log and grad_log. grdpPercap_log showed no significance. The coefficient of determination (\\(R^2\\)) was 0.6221, and the adjusted \\(R^2\\) was 0.6128. I considered this model sufficient to explain the relationship.\nUsing the result of the regression analysis, I evaluated the model’s performance with Root Mean Square Error (RMSE) and Mean Absolute Error (MAE).\n\nobs_val &lt;- TFR_log_sgg$tfr_log\npred_val_OLS &lt;- model_log$fitted.values\nres_OLS &lt;- obs_val - pred_val_OLS\n\nrmse_OLS &lt;- sqrt(mean(res_OLS^2))\nrmse_OLS\n\n[1] 0.1597133\n\nmae_OLS &lt;- mean(abs(res_OLS))\nmae_OLS\n\n[1] 0.1243839\n\n\n\n\nSpatial visualization\nBefore moving on to the local analysis, I wanted to see the distribution of the variables. So, I created choropleth maps for all the variables. To make a map, I joined table data containing the variables with the spatial data.\n\nlibrary(sf)\n\nsgg &lt;- st_read(\"bnd_sigungu_00_2020_2020_4Q.shp\", quiet = TRUE)\nsummary(sgg)\n\n  BASE_DATE          SIGUNGU_CD         SIGUNGU_NM             pop        \n Length:250         Length:250         Length:250         Min.   :  8444  \n Class :character   Class :character   Class :character   1st Qu.: 57312  \n Mode  :character   Mode  :character   Mode  :character   Median :174506  \n                                                          Mean   :207317  \n                                                          3rd Qu.:314999  \n                                                          Max.   :880859  \n    pop_den                  geometry  \n Min.   :   18.37   MULTIPOLYGON :250  \n 1st Qu.:  103.13   epsg:NA      :  0  \n Median :  625.48   +proj=tmer...:  0  \n Mean   : 3864.26                      \n 3rd Qu.: 5929.76                      \n Max.   :25143.33                      \n\nsgg$SIGUNGU_CD &lt;- as.integer(sgg$SIGUNGU_CD) # convert \"SIGUNGU_CD\" in \"sgg\" as integer\nsgg_TFR &lt;- sgg |&gt; # join table data with spatial data\n  left_join(TFR_log, join_by(SIGUNGU_CD == sgg)) |&gt; \n  select(-c(pop, pop_den))\nsummary(sgg_TFR)\n\n  BASE_DATE           SIGUNGU_CD     SIGUNGU_NM            name          \n Length:250         Min.   :11010   Length:250         Length:250        \n Class :character   1st Qu.:24043   Class :character   Class :character  \n Mode  :character   Median :32315   Mode  :character   Mode  :character  \n                    Mean   :29868                                        \n                    3rd Qu.:36328                                        \n                    Max.   :39020                                        \n     first           under6          tfr_log           popden_log    \n Min.   :28.34   Min.   : 3.831   Min.   :-0.80968   Min.   : 2.911  \n 1st Qu.:30.21   1st Qu.:10.660   1st Qu.:-0.24303   1st Qu.: 4.636  \n Median :30.66   Median :12.673   Median :-0.07850   Median : 6.439  \n Mean   :30.68   Mean   :12.900   Mean   :-0.08017   Mean   : 6.574  \n 3rd Qu.:31.09   3rd Qu.:14.771   3rd Qu.: 0.06321   3rd Qu.: 8.688  \n Max.   :32.49   Max.   :27.231   Max.   : 0.89813   Max.   :10.132  \n incentive_log       grad_log     grdpPercap_log           geometry  \n Min.   :0.0000   Min.   :1.873   Min.   :2.381   MULTIPOLYGON :250  \n 1st Qu.:0.3586   1st Qu.:2.524   1st Qu.:3.258   epsg:NA      :  0  \n Median :0.5798   Median :2.930   Median :3.493   +proj=tmer...:  0  \n Mean   :0.6271   Mean   :2.910   Mean   :3.523                      \n 3rd Qu.:0.8566   3rd Qu.:3.233   3rd Qu.:3.732                      \n Max.   :1.7888   Max.   :4.094   Max.   :6.077                      \n\n\nI used “sido” data for better visualization.\n\nlibrary(tmap)\nsido.shp &lt;- st_read(\"SIDO_2021_gen.shp\", quiet = TRUE) # sido is the largest administrative region in South Korea\ntm_shape(sgg_TFR) +\n  tm_polygons(\"tfr_log\", style = \"jenks\", palette = \"-PuOr\", border.col = \"gray20\", lwd = 1,\n              title = \"Total Fertility Rate(2020)\",\n              midpoint = 0\n              )+\n  tm_shape(sido.shp) +\n  tm_borders(col = \"black\", lwd = 2)\n\n\n\n\n\n\n\n\nI also made maps for the independent variables using a self-made function.\n\nvar_mapping &lt;- function(value, title) {\n  tm_shape(sgg_TFR) +\n    tm_polygons(value, style = \"jenks\", palette = \"BuPu\", border.col = \"gray20\", lwd = 1,\n                title = title) +\n    tm_shape(sido.shp) +\n    tm_borders(col = \"black\", lwd =2)\n}\n\n\nmap1 &lt;- var_mapping(\"popden_log\", \"Population Density(2020)\")\nmap2 &lt;- var_mapping(\"incentive_log\", \"Birth Incentive(2020)\")\nmap3 &lt;- var_mapping(\"grad_log\", \"Proportion of Women with College Degree of Higher(2020)\")\nmap4 &lt;- var_mapping(\"first\", \"Age of First Marriage for Women(2020)\")\nmap5 &lt;- var_mapping(\"under6\", \"Number of Childcare Facilities per 1,000 under 6(2020)\")\nmap6 &lt;- var_mapping(\"grdpPercap_log\", \"GRDP per Capita(2020)\")\n\ntmap_arrange(map1, map2, map3, map4, map5, map6, ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\nGWR and GRF will be introduced in the following posts."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\n\nB.A., 2024, Department of Geography Education, Seoul National University"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\n\nTeaching Assistant, Cartography, Spring Semester 2024\n\nServed as the lab instructor for QGIS exercises, guiding students through the practical application of cartographic principles in digital mapping.\n\nTeaching Assistant, Designing Human and Social Education Contents for AI Convergence Education, Spring Semester 2024\n\nServed as the lab instructor for R exercises, guiding teachers in basic data analysis with R.\n\nTeaching Assistant, AI and Digital Competency Enhancement Workshop for Pre-service Social Studies Teachers, Summer 2024\n\nLed a 5-day practical training on data collection, analysis, visualization, and dashboard development using R and Quarto."
  },
  {
    "objectID": "posts/2025-07-15 URF/index.html",
    "href": "posts/2025-07-15 URF/index.html",
    "title": "Hyperparameter Optimization for Unsupervised Random Forests",
    "section": "",
    "text": "Hi\n\n\n\nCitationBibTeX citation:@online{kim2024,\n  author = {Kim, Woohyung},\n  title = {Hyperparameter {Optimization} for {Unsupervised} {Random}\n    {Forests}},\n  date = {2024-07-03},\n  url = {https://geowhk.github.io/posts/2024-07-03-first-blog/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nKim, Woohyung. 2024. “Hyperparameter Optimization for Unsupervised\nRandom Forests.” July 3, 2024. https://geowhk.github.io/posts/2024-07-03-first-blog/."
  },
  {
    "objectID": "posts/2025-08-22-proposal/index.html",
    "href": "posts/2025-08-22-proposal/index.html",
    "title": "Idea for Master’s Thesis",
    "section": "",
    "text": "LLM은 근본적으로 텍스트 모델이기 때문에 단어와 문장의 순차적인 배열(시퀀스, sequence)를 처리하기 위해 설계된 언어 모델이다. 따라서 여러 노드와 엣지로 복잡하게 구성된 공간 상호작용 데이터를 잘 이해하지 못한다.\n\n(Tang et al., 2024)은 논문의 주제를 분류하는 과제에서 (a) 논문의 내용만 줬을 때, (b) 논문 내용과 인용 관계(그래프 구조)를 글로 풀어서 설명해 줬을 때, 그리고 (c) 그래프를 LLM과 결합한 GraphGPT를 사용했을 때의 성능을 비교함\n(a)는 잘못된 답을 내놨고, (b)는 입력 토큰 길이가 매우 길어졌으며 역시 부정확한 답을 내놓음.\nLLM이 그래프 구조를 텍스트로 이해하는 데에는 심각한 비효율성과 부정확성이 있음을 확인.\n\n연구를 통해 LLM이 공간적 상호작용 데이터를 정확하게 이해하고, 관련된 사용자의 질문에 정확하게 답변할 수 있도록 만든다.\n궁극적으로, 지금 ChatGPT나 Gemini가 이미지나 pdf를 이해하는 것처럼, 공간적 상호작용 그래프를 input으로 넣었을 때, 그것을 이해하고 관련된 질문에 답을 할 수 있게 만들 수 있다.\n만약 구글이 개발한 Population Dynamic Foundation Model처럼, 공간적 상호작용 데이터가 매우 방대한 규모로 연구된 “Spatial Interaction Foundation Model”이 있다면 이 연구에서 아이디어를 얻어 세상의 다양한 공간적 상호작용과 관련된 질의응답이 가능한 챗봇을 만들 수 있을 것이다."
  },
  {
    "objectID": "posts/2025-08-22-proposal/index.html#연구-주제-선정의-이유",
    "href": "posts/2025-08-22-proposal/index.html#연구-주제-선정의-이유",
    "title": "Idea for Master’s Thesis",
    "section": "",
    "text": "LLM은 근본적으로 텍스트 모델이기 때문에 단어와 문장의 순차적인 배열(시퀀스, sequence)를 처리하기 위해 설계된 언어 모델이다. 따라서 여러 노드와 엣지로 복잡하게 구성된 공간 상호작용 데이터를 잘 이해하지 못한다.\n\n(Tang et al., 2024)은 논문의 주제를 분류하는 과제에서 (a) 논문의 내용만 줬을 때, (b) 논문 내용과 인용 관계(그래프 구조)를 글로 풀어서 설명해 줬을 때, 그리고 (c) 그래프를 LLM과 결합한 GraphGPT를 사용했을 때의 성능을 비교함\n(a)는 잘못된 답을 내놨고, (b)는 입력 토큰 길이가 매우 길어졌으며 역시 부정확한 답을 내놓음.\nLLM이 그래프 구조를 텍스트로 이해하는 데에는 심각한 비효율성과 부정확성이 있음을 확인.\n\n연구를 통해 LLM이 공간적 상호작용 데이터를 정확하게 이해하고, 관련된 사용자의 질문에 정확하게 답변할 수 있도록 만든다.\n궁극적으로, 지금 ChatGPT나 Gemini가 이미지나 pdf를 이해하는 것처럼, 공간적 상호작용 그래프를 input으로 넣었을 때, 그것을 이해하고 관련된 질문에 답을 할 수 있게 만들 수 있다.\n만약 구글이 개발한 Population Dynamic Foundation Model처럼, 공간적 상호작용 데이터가 매우 방대한 규모로 연구된 “Spatial Interaction Foundation Model”이 있다면 이 연구에서 아이디어를 얻어 세상의 다양한 공간적 상호작용과 관련된 질의응답이 가능한 챗봇을 만들 수 있을 것이다."
  },
  {
    "objectID": "posts/2025-08-22-proposal/index.html#gnn과-llm-결합의-이유",
    "href": "posts/2025-08-22-proposal/index.html#gnn과-llm-결합의-이유",
    "title": "Idea for Master’s Thesis",
    "section": "GNN과 LLM 결합의 이유",
    "text": "GNN과 LLM 결합의 이유\n\nGNN만 썼을 때에 비해 나은 점\n\n공간적 상호작용 데이터에 대한 자연어 질문과 자연어 답변이 가능해짐\n공간적 상호작용 그래프 자체 뿐만 아니라 LLM에 사전학습된 정보까지 활용한 답변이 가능함\n\n\n\nLLM만 썼을 때에 비해 나은 점\n\n확장성: 거대한 상호작용 네트워크를 말로 설명하는 것은 매우 어려운데, GNN은 임베딩 벡터로 이 정보를 효율적으로 압축하여 LLM의 input으로 넣을 수 있음.\n구조적 추론과 암묵적 패턴 발견 가능: GNN을 통해 발견한 네트워크 상의 역할, 패턴을 LLM이 답변에 활용할 수 있음."
  },
  {
    "objectID": "posts/2025-08-22-proposal/index.html#text2gis랑-다른-점은",
    "href": "posts/2025-08-22-proposal/index.html#text2gis랑-다른-점은",
    "title": "Idea for Master’s Thesis",
    "section": "Text2GIS랑 다른 점은?",
    "text": "Text2GIS랑 다른 점은?\n\nText2GIS: 자연어 → LLM(SQL 쿼리 생성) → DB(실행) → 시각화\n상호작용 LLM: 그래프 → GNN 인코딩 → 어댑터 → LLM → 예측"
  }
]